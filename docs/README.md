# Interactive Academic CV Website

This directory contains your interactive academic CV website, ready for deployment to GitHub Pages.

## üåü Features

- **Modern, Responsive Design**: Works beautifully on desktop, tablet, and mobile
- **Dark Mode Toggle**: Automatic theme persistence with smooth transitions
- **Interactive Publications Filter**: Search and filter by type (journals, conferences, books, technical)
- **Research Metrics Dashboard**: Citations, h-index, publication counts, supervision statistics
- **Timeline Views**: Education and professional experience presented chronologically
- **Project Showcase**: Grid layout for research projects with funding information
- **Complete Academic Profile**: Education, positions, publications, projects, supervisions, awards

## üìÅ Files

- `index.html` - Main HTML structure
- `style.css` - Comprehensive styling with CSS variables for theming
- `script.js` - Interactive functionality (filtering, sorting, dark mode)
- `README.md` - This file

## üöÄ Deployment to GitHub Pages

### Option 1: Automatic (Recommended)

1. **Push to GitHub**:
   ```bash
   git add docs/
   git commit -m "Add interactive CV website"
   git push origin main
   ```

2. **Enable GitHub Pages**:
   - Go to your repository on GitHub
   - Navigate to **Settings** ‚Üí **Pages**
   - Under "Source", select **Deploy from a branch**
   - Select branch: **main**
   - Select folder: **/docs**
   - Click **Save**

3. **Access your site**:
   - Your CV will be available at: `https://YOUR-USERNAME.github.io/academic-cv/`
   - GitHub will provide the exact URL after deployment

### Option 2: Using GitHub Actions (Advanced)

Create `.github/workflows/deploy.yml`:

```yaml
name: Deploy to GitHub Pages

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Generate CV data
        run: |
          python scripts/consolidate_cv_data.py
      
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs
```

## üîÑ Updating Your CV

When you add new publications or update your profile:

1. **Update source data**:
   ```bash
   # Pull latest from ORCID, OpenAlex, etc.
   make update
   ```

2. **Regenerate CV data**:
   ```bash
   python scripts/consolidate_cv_data.py
   ```

3. **Test locally** (optional):
   ```bash
   # Serve locally on port 8000
   cd docs
   python -m http.server 8000
   # Open: http://localhost:8000
   ```

4. **Deploy**:
   ```bash
   git add .
   git commit -m "Update CV with latest publications"
   git push
   ```

## üé® Customization

### Colors and Theme

Edit CSS variables in `style.css`:

```css
:root {
    --primary-color: #2563eb;    /* Main blue */
    --accent-color: #f59e0b;     /* Gold accent */
    /* ... more variables ... */
}
```

### Adding Sections

1. Add HTML section in `index.html`
2. Add rendering function in `script.js`
3. Style in `style.css`

### Metrics Display

Modify the metrics shown in `script.js` ‚Üí `renderMetrics()`:

```javascript
const metrics = [
    { value: cvData.metrics.total_publications, label: 'Publications' },
    // Add your custom metrics here
];
```

## üß™ Local Testing

### Simple HTTP Server

```bash
cd docs
python -m http.server 8000
```

Open `http://localhost:8000` in your browser.

### Live Reload (Development)

Install live-server:
```bash
npm install -g live-server
cd docs
live-server
```

## üìä Data Source

The website reads from: `../data/processed/cv_data.json`

This file is generated by `scripts/consolidate_cv_data.py`, which merges:
- OpenAlex publications (with authors, citations, abstracts)
- Crossref enrichment (DOIs, funders)
- Lattes comprehensive CV (education, positions, projects, supervisions, awards)
- Markdown CV metadata

## üîç SEO and Metadata

To improve discoverability, add to `<head>` in `index.html`:

```html
<meta name="description" content="Academic CV of Carlos Denner dos Santos Jr. - Information Systems researcher and data science consultant">
<meta name="keywords" content="academic cv, data science, information systems, open source">
<meta name="author" content="Carlos Denner dos Santos Jr.">
<meta property="og:title" content="Carlos Denner dos Santos Jr. - Academic CV">
<meta property="og:description" content="Information Systems researcher with 20+ years experience">
<meta property="og:type" content="profile">
```

## üêõ Troubleshooting

### CV data not loading

1. Check browser console (F12) for errors
2. Verify `cv_data.json` exists in `data/processed/`
3. Ensure JSON is valid: `python -m json.tool data/processed/cv_data.json`

### GitHub Pages not updating

1. Check Actions tab for build errors
2. Clear browser cache
3. Verify GitHub Pages is enabled in Settings
4. Wait 2-3 minutes for deployment

### Styling issues

1. Hard refresh: Ctrl+F5 (Windows) or Cmd+Shift+R (Mac)
2. Check for CSS syntax errors
3. Verify CSS file is loading (Network tab in DevTools)

## üì± Mobile Optimization

The site is fully responsive with breakpoints at:
- Desktop: > 768px
- Tablet: 768px
- Mobile: < 768px

Test responsiveness in browser DevTools (F12 ‚Üí Toggle device toolbar).

## ‚ö° Performance

Current optimization:
- Minimal external dependencies (only Font Awesome for icons)
- CSS and JS are minified for production
- Images optimized and lazy-loaded
- Total page size: ~200KB

## üîí Privacy

The website is static (no server-side code) and:
- Does not collect user data
- Does not use cookies
- Does not track visitors
- All data is public from academic sources

## üìÑ License

This CV website template is provided as-is for academic use. The content (publications, bio) remains ¬© Carlos Denner dos Santos Jr.

## ü§ù Contributing

To improve the CV pipeline:

1. Update data extraction scripts in `scripts/`
2. Regenerate CV data: `python scripts/consolidate_cv_data.py`
3. Test the website locally
4. Submit improvements via pull request

## üìû Support

For issues with:
- **Website**: Check browser console, verify JSON data
- **Data pipeline**: Run `python scripts/normalize_dedupe.py` to check for errors
- **GitHub Pages**: Check repository Actions tab

---

**Last Updated**: 2025-11-11  
**Generated by**: Academic CV Automation Pipeline  
**Data Sources**: ORCID, OpenAlex, Crossref, Google Scholar, ResearchGate, Lattes CV
